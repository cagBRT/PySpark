{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOFnY8wccCu/qzOrqLJT1da",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/PySpark/blob/master/PySpark_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LsDoJopTa8Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/PySpark.git cloned-repo\n",
        "#%cd cloned-repo\n",
        "#!ls"
      ],
      "metadata": {
        "id": "CgduyP92Uv5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    return Image(\"/content/cloned-repo/\"+str(num)+ \".png\" , width=640)"
      ],
      "metadata": {
        "id": "fS83pNJuVBA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7wQrL7jJVKM"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "# Create a Spark Session\n",
        "#getOrCreate gets or creates a session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Check Spark Session Information\n",
        "spark"
      ],
      "metadata": {
        "id": "BYmRHz5mJeWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import a Spark function from library\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "4fmKVmnaJipv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "print(\"If no error - everything is working\")\n"
      ],
      "metadata": {
        "id": "o3WlhnO8JmLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "y3LaVsmtIcS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tools we need to connect to the Spark server, load our data,\n",
        "# clean it and prepare it\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col"
      ],
      "metadata": {
        "id": "d8swmeMGJsUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zPEx-WZvJy56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StringIndexer<br>\n",
        "Use stringIndexer when you want a column identified as catagorical data. "
      ],
      "metadata": {
        "id": "WwdwZja686ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StringIndexer maps a string column to a index column that will be treated as a categorical column by spark. The indices start with 0 and are ordered by label frequencies. If it is a numerical column, the column will be cast as a string column and then indexed by StringIndexer.\n",
        "\n",
        "There are three steps to implement the StringIndexer\n",
        "\n",
        "Build the StringIndexer model: specify the input column and output column names.\n",
        "Learn the StringIndexer model: fit the model with your data.\n",
        "Execute the indexing: call the transform function to execute the indexing process."
      ],
      "metadata": {
        "id": "lWuvYjaeLjtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StringIndexer maps a string column to a index column that will be treated as a categorical column by spark. The indices start with 0 and are ordered by label frequencies. If it is a numerical column, the column will be cast as a string column and then indexed by StringIndexer.\n",
        "\n",
        "There are three steps to implement the StringIndexer\n",
        "\n",
        "Build the StringIndexer model: specify the input column and output column names.\n",
        "Learn the StringIndexer model: fit the model with your data.\n",
        "Execute the indexing: call the transform function to execute the indexing process."
      ],
      "metadata": {
        "id": "valBAeQCbgkQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2gSHi0da3pF"
      },
      "outputs": [],
      "source": [
        "\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
        "        'y1': [1, 0, 1, 0, 0, 1],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
        "    })\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# build indexer\n",
        "string_indexer = StringIndexer(inputCol='x1', outputCol='indexed_x1')\n",
        "\n",
        "# learn the model\n",
        "string_indexer_model = string_indexer.fit(df)\n",
        "\n",
        "# transform the data\n",
        "df_stringindexer = string_indexer_model.transform(df)\n",
        "\n",
        "# resulting df\n",
        "df_stringindexer.show()"
      ],
      "metadata": {
        "id": "cilw1neYKGP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice in the indexed_x1 column the value 'b' is the most numerous so it get the value 0<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "HjBX3uz49ggr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment<br>\n",
        "Column x2 contains catagorical data. <br>\n",
        "Convert it to data the ML model can use. "
      ],
      "metadata": {
        "id": "_es_es6992BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assignment\n"
      ],
      "metadata": {
        "id": "hkDWR0R8-CYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \n",
        "# build indexer\n",
        "string_indexer = StringIndexer(inputCol='x2', outputCol='indexed_x2')\n",
        "\n",
        "# learn the model\n",
        "string_indexer_model = string_indexer.fit(df_stringindexer)\n",
        "\n",
        "# transform the data\n",
        "df_stringindexer = string_indexer_model.transform(df_stringindexer)\n",
        "\n",
        "# resulting df\n",
        "df_stringindexer.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ti1sWuVv9Nmm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}